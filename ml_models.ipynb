{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f9d7de4-f27a-413b-a7d3-9aab3c917b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs:  5\n",
      "Batch size:  128\n",
      "\n",
      "Loading dataset...\n",
      "\n",
      "After stacking...\n",
      "trainX.shape:  (1557162, 115, 1)\n",
      "testX.shape:  (173018, 115, 1)\n",
      "\n",
      "After categorizing...\n",
      "trainy.shape:  (1557162, 11)\n",
      "testy.shape:  (173018, 11) \n",
      "\n",
      "Evaluating for C:\\Users\\nalla\\OneDrive\\Provision_PT_838\\dataset\\Data...\n",
      "\n",
      "Repeat:  1\n",
      "Training model with learning rate: 0.005\n",
      "Training model 1...\n",
      "Training model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nalla\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m12166/12166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2196s\u001b[0m 180ms/step - accuracy: 0.8930 - loss: 0.0886\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nalla\\anaconda3\\Lib\\site-packages\\keras\\src\\callbacks\\early_stopping.py:156: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12166/12166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1937s\u001b[0m 159ms/step - accuracy: 0.9063 - loss: 0.0611\n",
      "Epoch 3/5\n",
      "\u001b[1m12166/12166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2110s\u001b[0m 173ms/step - accuracy: 0.9074 - loss: 0.0597\n",
      "Epoch 4/5\n",
      "\u001b[1m12166/12166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2219s\u001b[0m 182ms/step - accuracy: 0.9069 - loss: 0.0604\n",
      "Epoch 5/5\n",
      "\u001b[1m12166/12166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2262s\u001b[0m 186ms/step - accuracy: 0.9086 - loss: 0.0589\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 60ms/step\n",
      "Accuracy with learning rate 0.005: 0.9665352737865425\n",
      "F1 Score: 0.9643635323870519\n",
      "Recall: 0.9665352737865425\n",
      "Precision: 0.9734967301625667\n",
      "Confusion Matrix:\n",
      "[[98528     0     0     0     0     1     0     0     0     0     0]\n",
      " [    3  5323   299    11     0     0     5     0     1     1     0]\n",
      " [    2   316  2579     4     0     0     0     0     0     0     0]\n",
      " [    2     0     0  2817     0     0     0     0     0     0     0]\n",
      " [    7     0     0     0  8944     1     0     0     0     2     0]\n",
      " [   11     0     0     0     0 10397     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0  3863     0     0  2266     0]\n",
      " [    0     0     0     0     0     0     0  9633     0     0     0]\n",
      " [    2    10    39     0     0     0     0     0  6625     0     0]\n",
      " [    0     0     0     0     0     0     7     0     0 15741     0]\n",
      " [    0     0     0     0     0     0    24     0     0  2776  2778]]\n",
      "Duration of loading data: 82 seconds\n",
      "Duration of evaluating model: 11853 seconds\n",
      "Duration of whole experiment: 11936 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import time\n",
    "from sklearn.utils import resample\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy import mean, std, dstack\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Declare a global variable to store the results\n",
    "global_results = {}\n",
    "\n",
    "def load_dataset(path):\n",
    "    # Load input data and output data\n",
    "    print('\\nLoading dataset...')\n",
    "    files = os.listdir(path)\n",
    "    dataX_files = [file for file in files if 'x_' in file]\n",
    "    datay_files = [file for file in files if 'y_' in file]\n",
    "    dataX_files.sort()\n",
    "    datay_files.sort()\n",
    "\n",
    "    dataX = pd.concat([pd.read_csv(path + '/' + file, delimiter=',') for file in dataX_files])\n",
    "    \n",
    "    datay = pd.DataFrame()  # Initialize datay as an empty DataFrame\n",
    "    unique_label = 1\n",
    "    for file in datay_files:\n",
    "        datay_temp = pd.read_csv(path + '/' + file, delimiter=',')\n",
    "        if (datay_temp.iloc[:, 0] == 1).any():  # Check if there are any 1 values in the first column\n",
    "            datay_temp.loc[datay_temp.iloc[:, 0] == 1, datay_temp.columns[0]] = unique_label\n",
    "            if datay.empty:  # If datay is empty, directly assign datay_temp\n",
    "                datay = datay_temp\n",
    "            else:\n",
    "                datay = pd.concat([datay, datay_temp])  # Append only the modified datay_temp\n",
    "            unique_label += 1\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    trainX, testX = model_selection.train_test_split(dataX, test_size=0.10, random_state=42, shuffle=True)\n",
    "    trainy, testy = model_selection.train_test_split(datay, test_size=0.10, random_state=42, shuffle=True)\n",
    "\n",
    "    # Get 3D training data (assuming your data requires this step)\n",
    "    listtrain = [trainX]\n",
    "    listtest = [testX]\n",
    "    trainX = dstack(listtrain)\n",
    "    testX = dstack(listtest)\n",
    "    print('\\nAfter stacking...')\n",
    "    print('trainX.shape: ', trainX.shape)\n",
    "    print('testX.shape: ', testX.shape)\n",
    "\n",
    "    # Calculate number of classes based on unique values in trainy\n",
    "    num_classes = np.unique(trainy).shape[0]\n",
    "\n",
    "    # Convert output data to categorical form\n",
    "    trainy = to_categorical(trainy.values.ravel(), num_classes=num_classes)\n",
    "    testy = to_categorical(testy.values.ravel(), num_classes=num_classes)\n",
    "    print('\\nAfter categorizing...')\n",
    "    print('trainy.shape: ', trainy.shape)\n",
    "    print('testy.shape: ', testy.shape, '\\n')\n",
    "\n",
    "    return trainX, trainy, testX, testy\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import time\n",
    "epochs, batch_size = 5, 128  # Reduced number of epochs and increased batch size\n",
    "print('Number of epochs: ', epochs)\n",
    "print('Batch size: ', batch_size),\n",
    "# Declare a global variable to store the results\n",
    "global_results = {}\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    n_features, n_added_dimension, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\n",
    "    # Calculate class weights\n",
    "    y_integers = np.argmax(trainy, axis=1)\n",
    "    class_weights = class_weight.compute_sample_weight('balanced', y_integers)\n",
    "    d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "    # Define your learning rates\n",
    "    learning_rates = [0.005]\n",
    "\n",
    "    # Initialize a list to store the predictions from each model\n",
    "    ensemble_predictions = []\n",
    "\n",
    "    for lr in learning_rates:\n",
    "        \n",
    "        print(f'Training model with learning rate: {lr}')\n",
    "\n",
    "        for i in range(2):  # Train 2 models\n",
    "            print(f'Training model {i+1}...')\n",
    "\n",
    "            # Randomly sample instances from the training data\n",
    "            indices = np.arange(trainX.shape[0])\n",
    "            sample_indices = resample(indices, replace=True)\n",
    "            sample_X, sample_y = trainX[sample_indices], trainy[sample_indices]\n",
    "\n",
    "            if i == 0:\n",
    "                # Flatten the data for Random Forest\n",
    "                trainX_flat = sample_X.reshape(sample_X.shape[0], -1)\n",
    "\n",
    "                # Convert categorical labels back to 1-D for Random Forest\n",
    "                trainy_flat = np.argmax(sample_y, axis=1)\n",
    "\n",
    "                # Define the model with depth 4\n",
    "                model = RandomForestClassifier(n_estimators=100, max_depth=4)\n",
    "                model.fit(trainX_flat, trainy_flat)\n",
    "\n",
    "                # Predict the test set results for RandomForestClassifier\n",
    "                testX_flat = testX.reshape(testX.shape[0], -1)\n",
    "                y_pred = model.predict_proba(testX_flat)\n",
    "\n",
    "            else:\n",
    "                # Define the LSTM model for the second iteration\n",
    "                model = Sequential()\n",
    "                model.add(LSTM(100, input_shape=(n_features, n_added_dimension), return_sequences=True))\n",
    "                model.add(Dropout(0.2))\n",
    "                model.add(Conv1D(64, 3, activation='relu'))\n",
    "                model.add(MaxPooling1D(pool_size=2))\n",
    "                model.add(Flatten())\n",
    "                model.add(Dense(50, activation='relu'))\n",
    "                model.add(Dense(n_outputs, activation='softmax'))\n",
    "\n",
    "                model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=lr), metrics=['accuracy'])\n",
    "\n",
    "                # Use early stopping\n",
    "                early_stopping = EarlyStopping(monitor='val_loss', patience=5) \n",
    "                model.fit(sample_X, sample_y, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[early_stopping], class_weight=d_class_weights)\n",
    "\n",
    "                # Predict the test set results for LSTM model\n",
    "                y_pred = model.predict(testX, batch_size=batch_size)\n",
    "\n",
    "            ensemble_predictions.append(y_pred)\n",
    "\n",
    "        # Combine the predictions from each model\n",
    "        ensemble_predictions = np.array(ensemble_predictions)\n",
    "        ensemble_y_pred = np.argmax(np.mean(ensemble_predictions, axis=0), axis=-1)\n",
    "\n",
    "                # Convert testy from multilabel-indicator format to multiclass format\n",
    "        testy_multiclass = np.argmax(testy, axis=1)\n",
    "        \n",
    "        # Calculate Accuracy, F1 score, Recall, and Precision\n",
    "        accuracy = accuracy_score(testy_multiclass, ensemble_y_pred)\n",
    "        f1 = f1_score(testy_multiclass, ensemble_y_pred, average='weighted')\n",
    "        recall = recall_score(testy_multiclass, ensemble_y_pred, average='weighted')\n",
    "        precision = precision_score(testy_multiclass, ensemble_y_pred, average='weighted')\n",
    "        \n",
    "        print(f'Accuracy with learning rate {lr}: {accuracy}')\n",
    "        print(f'F1 Score: {f1}')\n",
    "        print(f'Recall: {recall}')\n",
    "        print(f'Precision: {precision}')\n",
    "        cm = confusion_matrix(testy_multiclass, ensemble_y_pred)\n",
    "        print('Confusion Matrix:')\n",
    "        print(cm)\n",
    "\n",
    "    return accuracy, f1, recall, precision\n",
    "\n",
    "\n",
    "\n",
    "def run_experiment(repeats, datasetname):\n",
    "    experiment_start_time = time.time()\n",
    "    trainX, trainy, testX, testy = load_dataset(datasetname)\n",
    "    print('Evaluating for ' + datasetname + '...\\n')\n",
    "    data_loading_time = time.time()\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        print('Repeat: ', r + 1)\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "    print(\"Duration of loading data: %d seconds\" % (data_loading_time - experiment_start_time))\n",
    "    print(\"Duration of evaluating model: %d seconds\" % (time.time() - data_loading_time))\n",
    "    print(\"Duration of whole experiment: %d seconds\" % (time.time() - experiment_start_time))\n",
    "    \n",
    "run_experiment(1,'C:\\\\Users\\\\nalla\\\\OneDrive\\\\Provision_PT_838\\\\dataset\\\\Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d40b57ae-800b-4e0f-acb9-e7383d898ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs:  5\n",
      "Batch size:  128\n",
      "\n",
      "Loading dataset...\n",
      "\n",
      "After stacking...\n",
      "trainX.shape:  (1557162, 115, 1)\n",
      "testX.shape:  (173018, 115, 1)\n",
      "\n",
      "After categorizing...\n",
      "trainy.shape:  (1557162, 11)\n",
      "testy.shape:  (173018, 11) \n",
      "\n",
      "Evaluating for C:\\Users\\nalla\\OneDrive\\Provision_PT_838\\dataset\\Data...\n",
      "\n",
      "Repeat:  1\n",
      "Training model with learning rate: 0.01\n",
      "Training model 1...\n",
      "Training model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nalla\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m12166/12166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1665s\u001b[0m 137ms/step - accuracy: 0.8892 - loss: 0.1155\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nalla\\anaconda3\\Lib\\site-packages\\keras\\src\\callbacks\\early_stopping.py:156: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12166/12166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1735s\u001b[0m 143ms/step - accuracy: 0.9003 - loss: 0.0679\n",
      "Epoch 3/5\n",
      "\u001b[1m12166/12166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1788s\u001b[0m 147ms/step - accuracy: 0.8971 - loss: 0.0679\n",
      "Epoch 4/5\n",
      "\u001b[1m12166/12166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1809s\u001b[0m 149ms/step - accuracy: 0.9033 - loss: 0.0645\n",
      "Epoch 5/5\n",
      "\u001b[1m12166/12166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1953s\u001b[0m 161ms/step - accuracy: 0.8904 - loss: 0.0710\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 63ms/step\n",
      "Accuracy with learning rate 0.01: 0.9588250933428892\n",
      "F1 Score: 0.955077980268233\n",
      "Recall: 0.9588250933428892\n",
      "Precision: 0.9681444871602907\n",
      "Confusion Matrix:\n",
      "[[98523     0     0     0     0     6     0     0     0     0     0]\n",
      " [    1  5574    22     9     0     0     0     0    28     9     0]\n",
      " [    2  1670  1185     3     0     0     0     0    39     2     0]\n",
      " [    2     0     0  2817     0     0     0     0     0     0     0]\n",
      " [   14     0     0     0  8939     1     0     0     0     0     0]\n",
      " [   11     0     0     0     0 10397     0     0     0     0     0]\n",
      " [    2     0     0     0     0     0  3666     0     0  2461     0]\n",
      " [    0     0     0     0     0     0     0  9633     0     0     0]\n",
      " [    0     0    32     0     0     0     0     0  6642     2     0]\n",
      " [    2     0     0     0     0     0     5     0     0 15741     0]\n",
      " [    3     0     0     0     0     0     2     0     0  2796  2777]]\n",
      "Duration of loading data: 34 seconds\n",
      "Duration of evaluating model: 9532 seconds\n",
      "Duration of whole experiment: 9567 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import time\n",
    "from sklearn.utils import resample\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy import mean, std, dstack\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Declare a global variable to store the results\n",
    "global_results = {}\n",
    "\n",
    "def load_dataset(path):\n",
    "    # Load input data and output data\n",
    "    print('\\nLoading dataset...')\n",
    "    files = os.listdir(path)\n",
    "    dataX_files = [file for file in files if 'x_' in file]\n",
    "    datay_files = [file for file in files if 'y_' in file]\n",
    "    dataX_files.sort()\n",
    "    datay_files.sort()\n",
    "\n",
    "    dataX = pd.concat([pd.read_csv(path + '/' + file, delimiter=',') for file in dataX_files])\n",
    "    \n",
    "    datay = pd.DataFrame()  # Initialize datay as an empty DataFrame\n",
    "    unique_label = 1\n",
    "    for file in datay_files:\n",
    "        datay_temp = pd.read_csv(path + '/' + file, delimiter=',')\n",
    "        if (datay_temp.iloc[:, 0] == 1).any():  # Check if there are any 1 values in the first column\n",
    "            datay_temp.loc[datay_temp.iloc[:, 0] == 1, datay_temp.columns[0]] = unique_label\n",
    "            if datay.empty:  # If datay is empty, directly assign datay_temp\n",
    "                datay = datay_temp\n",
    "            else:\n",
    "                datay = pd.concat([datay, datay_temp])  # Append only the modified datay_temp\n",
    "            unique_label += 1\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    trainX, testX = model_selection.train_test_split(dataX, test_size=0.10, random_state=42, shuffle=True)\n",
    "    trainy, testy = model_selection.train_test_split(datay, test_size=0.10, random_state=42, shuffle=True)\n",
    "\n",
    "    # Get 3D training data (assuming your data requires this step)\n",
    "    listtrain = [trainX]\n",
    "    listtest = [testX]\n",
    "    trainX = dstack(listtrain)\n",
    "    testX = dstack(listtest)\n",
    "    print('\\nAfter stacking...')\n",
    "    print('trainX.shape: ', trainX.shape)\n",
    "    print('testX.shape: ', testX.shape)\n",
    "\n",
    "    # Calculate number of classes based on unique values in trainy\n",
    "    num_classes = np.unique(trainy).shape[0]\n",
    "\n",
    "    # Convert output data to categorical form\n",
    "    trainy = to_categorical(trainy.values.ravel(), num_classes=num_classes)\n",
    "    testy = to_categorical(testy.values.ravel(), num_classes=num_classes)\n",
    "    print('\\nAfter categorizing...')\n",
    "    print('trainy.shape: ', trainy.shape)\n",
    "    print('testy.shape: ', testy.shape, '\\n')\n",
    "\n",
    "    return trainX, trainy, testX, testy\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import time\n",
    "epochs, batch_size = 5, 128  # Reduced number of epochs and increased batch size\n",
    "print('Number of epochs: ', epochs)\n",
    "print('Batch size: ', batch_size),\n",
    "# Declare a global variable to store the results\n",
    "global_results = {}\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    n_features, n_added_dimension, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\n",
    "    # Calculate class weights\n",
    "    y_integers = np.argmax(trainy, axis=1)\n",
    "    class_weights = class_weight.compute_sample_weight('balanced', y_integers)\n",
    "    d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "    # Define your learning rates\n",
    "    learning_rates = [0.01]\n",
    "\n",
    "    # Initialize a list to store the predictions from each model\n",
    "    ensemble_predictions = []\n",
    "\n",
    "    for lr in learning_rates:\n",
    "        \n",
    "        print(f'Training model with learning rate: {lr}')\n",
    "\n",
    "        for i in range(2):  # Train 2 models\n",
    "            print(f'Training model {i+1}...')\n",
    "\n",
    "            # Randomly sample instances from the training data\n",
    "            indices = np.arange(trainX.shape[0])\n",
    "            sample_indices = resample(indices, replace=True)\n",
    "            sample_X, sample_y = trainX[sample_indices], trainy[sample_indices]\n",
    "\n",
    "            if i == 0:\n",
    "                # Flatten the data for Random Forest\n",
    "                trainX_flat = sample_X.reshape(sample_X.shape[0], -1)\n",
    "\n",
    "                # Convert categorical labels back to 1-D for Random Forest\n",
    "                trainy_flat = np.argmax(sample_y, axis=1)\n",
    "\n",
    "                # Define the model with depth 4\n",
    "                model = RandomForestClassifier(n_estimators=100, max_depth=4)\n",
    "                model.fit(trainX_flat, trainy_flat)\n",
    "\n",
    "                # Predict the test set results for RandomForestClassifier\n",
    "                testX_flat = testX.reshape(testX.shape[0], -1)\n",
    "                y_pred = model.predict_proba(testX_flat)\n",
    "\n",
    "            else:\n",
    "                # Define the LSTM model for the second iteration\n",
    "                model = Sequential()\n",
    "                model.add(LSTM(100, input_shape=(n_features, n_added_dimension), return_sequences=True))\n",
    "                model.add(Dropout(0.2))\n",
    "                model.add(Conv1D(64, 3, activation='relu'))\n",
    "                model.add(MaxPooling1D(pool_size=2))\n",
    "                model.add(Flatten())\n",
    "                model.add(Dense(50, activation='relu'))\n",
    "                model.add(Dense(n_outputs, activation='softmax'))\n",
    "\n",
    "                model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=lr), metrics=['accuracy'])\n",
    "\n",
    "                # Use early stopping\n",
    "                early_stopping = EarlyStopping(monitor='val_loss', patience=5) \n",
    "                model.fit(sample_X, sample_y, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[early_stopping], class_weight=d_class_weights)\n",
    "\n",
    "                # Predict the test set results for LSTM model\n",
    "                y_pred = model.predict(testX, batch_size=batch_size)\n",
    "\n",
    "            ensemble_predictions.append(y_pred)\n",
    "\n",
    "        # Combine the predictions from each model\n",
    "        ensemble_predictions = np.array(ensemble_predictions)\n",
    "        ensemble_y_pred = np.argmax(np.mean(ensemble_predictions, axis=0), axis=-1)\n",
    "\n",
    "                # Convert testy from multilabel-indicator format to multiclass format\n",
    "        testy_multiclass = np.argmax(testy, axis=1)\n",
    "        \n",
    "        # Calculate Accuracy, F1 score, Recall, and Precision\n",
    "        accuracy = accuracy_score(testy_multiclass, ensemble_y_pred)\n",
    "        f1 = f1_score(testy_multiclass, ensemble_y_pred, average='weighted')\n",
    "        recall = recall_score(testy_multiclass, ensemble_y_pred, average='weighted')\n",
    "        precision = precision_score(testy_multiclass, ensemble_y_pred, average='weighted')\n",
    "        \n",
    "        print(f'Accuracy with learning rate {lr}: {accuracy}')\n",
    "        print(f'F1 Score: {f1}')\n",
    "        print(f'Recall: {recall}')\n",
    "        print(f'Precision: {precision}')\n",
    "        cm = confusion_matrix(testy_multiclass, ensemble_y_pred)\n",
    "        print('Confusion Matrix:')\n",
    "        print(cm)\n",
    "\n",
    "    return accuracy, f1, recall, precision\n",
    "\n",
    "\n",
    "\n",
    "def run_experiment(repeats, datasetname):\n",
    "    experiment_start_time = time.time()\n",
    "    trainX, trainy, testX, testy = load_dataset(datasetname)\n",
    "    print('Evaluating for ' + datasetname + '...\\n')\n",
    "    data_loading_time = time.time()\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        print('Repeat: ', r + 1)\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "    print(\"Duration of loading data: %d seconds\" % (data_loading_time - experiment_start_time))\n",
    "    print(\"Duration of evaluating model: %d seconds\" % (time.time() - data_loading_time))\n",
    "    print(\"Duration of whole experiment: %d seconds\" % (time.time() - experiment_start_time))\n",
    "    \n",
    "run_experiment(1,'C:\\\\Users\\\\nalla\\\\OneDrive\\\\Provision_PT_838\\\\dataset\\\\Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "febea901-eae9-4e30-b671-d8809014f9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs:  5\n",
      "Batch size:  128\n",
      "\n",
      "Loading dataset...\n",
      "\n",
      "After stacking...\n",
      "trainX.shape:  (1557162, 115, 1)\n",
      "testX.shape:  (173018, 115, 1)\n",
      "\n",
      "After categorizing...\n",
      "trainy.shape:  (1557162, 11)\n",
      "testy.shape:  (173018, 11) \n",
      "\n",
      "Evaluating for C:\\Users\\nalla\\OneDrive\\Provision_PT_838\\dataset\\Data...\n",
      "\n",
      "Repeat:  1\n",
      "Training model with learning rate: 0.0005\n",
      "Training model 1...\n",
      "Training model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nalla\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m12166/12166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1722s\u001b[0m 141ms/step - accuracy: 0.8957 - loss: 0.0962\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nalla\\anaconda3\\Lib\\site-packages\\keras\\src\\callbacks\\early_stopping.py:156: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12166/12166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1756s\u001b[0m 144ms/step - accuracy: 0.9353 - loss: 0.0378\n",
      "Epoch 3/5\n",
      "\u001b[1m12166/12166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1901s\u001b[0m 156ms/step - accuracy: 0.9382 - loss: 0.0347\n",
      "Epoch 4/5\n",
      "\u001b[1m12166/12166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2038s\u001b[0m 167ms/step - accuracy: 0.9392 - loss: 0.0332\n",
      "Epoch 5/5\n",
      "\u001b[1m12166/12166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4421s\u001b[0m 363ms/step - accuracy: 0.9403 - loss: 0.0311\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 114ms/step\n",
      "Accuracy with learning rate 0.0005: 0.9938908090487695\n",
      "F1 Score: 0.9937173464297814\n",
      "Recall: 0.9938908090487695\n",
      "Precision: 0.9942445680679182\n",
      "Confusion Matrix:\n",
      "[[98528     0     0     0     0     1     0     0     0     0     0]\n",
      " [    4  5621     4     2     0     0     0     1    11     0     0]\n",
      " [    2     1  2894     1     0     0     0     0     3     0     0]\n",
      " [    2     0     0  2817     0     0     0     0     0     0     0]\n",
      " [    1     0     0     0  8952     1     0     0     0     0     0]\n",
      " [    4     0     0     0     0 10404     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0  5113     0     0  1016     0]\n",
      " [    0     0     0     0     0     0     0  9633     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0  6676     0     0]\n",
      " [    0     0     0     0     0     0     2     0     0 15746     0]\n",
      " [    0     0     0     0     0     0     0     0     0     1  5577]]\n",
      "Duration of loading data: 35 seconds\n",
      "Duration of evaluating model: 12473 seconds\n",
      "Duration of whole experiment: 12508 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import time\n",
    "from sklearn.utils import resample\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy import mean, std, dstack\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Declare a global variable to store the results\n",
    "global_results = {}\n",
    "\n",
    "def load_dataset(path):\n",
    "    # Load input data and output data\n",
    "    print('\\nLoading dataset...')\n",
    "    files = os.listdir(path)\n",
    "    dataX_files = [file for file in files if 'x_' in file]\n",
    "    datay_files = [file for file in files if 'y_' in file]\n",
    "    dataX_files.sort()\n",
    "    datay_files.sort()\n",
    "\n",
    "    dataX = pd.concat([pd.read_csv(path + '/' + file, delimiter=',') for file in dataX_files])\n",
    "    \n",
    "    datay = pd.DataFrame()  # Initialize datay as an empty DataFrame\n",
    "    unique_label = 1\n",
    "    for file in datay_files:\n",
    "        datay_temp = pd.read_csv(path + '/' + file, delimiter=',')\n",
    "        if (datay_temp.iloc[:, 0] == 1).any():  # Check if there are any 1 values in the first column\n",
    "            datay_temp.loc[datay_temp.iloc[:, 0] == 1, datay_temp.columns[0]] = unique_label\n",
    "            if datay.empty:  # If datay is empty, directly assign datay_temp\n",
    "                datay = datay_temp\n",
    "            else:\n",
    "                datay = pd.concat([datay, datay_temp])  # Append only the modified datay_temp\n",
    "            unique_label += 1\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    trainX, testX = model_selection.train_test_split(dataX, test_size=0.10, random_state=42, shuffle=True)\n",
    "    trainy, testy = model_selection.train_test_split(datay, test_size=0.10, random_state=42, shuffle=True)\n",
    "\n",
    "    # Get 3D training data (assuming your data requires this step)\n",
    "    listtrain = [trainX]\n",
    "    listtest = [testX]\n",
    "    trainX = dstack(listtrain)\n",
    "    testX = dstack(listtest)\n",
    "    print('\\nAfter stacking...')\n",
    "    print('trainX.shape: ', trainX.shape)\n",
    "    print('testX.shape: ', testX.shape)\n",
    "\n",
    "    # Calculate number of classes based on unique values in trainy\n",
    "    num_classes = np.unique(trainy).shape[0]\n",
    "\n",
    "    # Convert output data to categorical form\n",
    "    trainy = to_categorical(trainy.values.ravel(), num_classes=num_classes)\n",
    "    testy = to_categorical(testy.values.ravel(), num_classes=num_classes)\n",
    "    print('\\nAfter categorizing...')\n",
    "    print('trainy.shape: ', trainy.shape)\n",
    "    print('testy.shape: ', testy.shape, '\\n')\n",
    "\n",
    "    return trainX, trainy, testX, testy\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import time\n",
    "epochs, batch_size = 5, 128  # Reduced number of epochs and increased batch size\n",
    "print('Number of epochs: ', epochs)\n",
    "print('Batch size: ', batch_size),\n",
    "# Declare a global variable to store the results\n",
    "global_results = {}\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    n_features, n_added_dimension, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\n",
    "    # Calculate class weights\n",
    "    y_integers = np.argmax(trainy, axis=1)\n",
    "    class_weights = class_weight.compute_sample_weight('balanced', y_integers)\n",
    "    d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "    # Define your learning rates\n",
    "    learning_rates = [0.0005]\n",
    "\n",
    "    # Initialize a list to store the predictions from each model\n",
    "    ensemble_predictions = []\n",
    "\n",
    "    for lr in learning_rates:\n",
    "        \n",
    "        print(f'Training model with learning rate: {lr}')\n",
    "\n",
    "        for i in range(2):  # Train 2 models\n",
    "            print(f'Training model {i+1}...')\n",
    "\n",
    "            # Randomly sample instances from the training data\n",
    "            indices = np.arange(trainX.shape[0])\n",
    "            sample_indices = resample(indices, replace=True)\n",
    "            sample_X, sample_y = trainX[sample_indices], trainy[sample_indices]\n",
    "\n",
    "            if i == 0:\n",
    "                # Flatten the data for Random Forest\n",
    "                trainX_flat = sample_X.reshape(sample_X.shape[0], -1)\n",
    "\n",
    "                # Convert categorical labels back to 1-D for Random Forest\n",
    "                trainy_flat = np.argmax(sample_y, axis=1)\n",
    "\n",
    "                # Define the model with depth 4\n",
    "                model = RandomForestClassifier(n_estimators=100, max_depth=4)\n",
    "                model.fit(trainX_flat, trainy_flat)\n",
    "\n",
    "                # Predict the test set results for RandomForestClassifier\n",
    "                testX_flat = testX.reshape(testX.shape[0], -1)\n",
    "                y_pred = model.predict_proba(testX_flat)\n",
    "\n",
    "            else:\n",
    "                # Define the LSTM model for the second iteration\n",
    "                model = Sequential()\n",
    "                model.add(LSTM(100, input_shape=(n_features, n_added_dimension), return_sequences=True))\n",
    "                model.add(Dropout(0.2))\n",
    "                model.add(Conv1D(64, 3, activation='relu'))\n",
    "                model.add(MaxPooling1D(pool_size=2))\n",
    "                model.add(Flatten())\n",
    "                model.add(Dense(50, activation='relu'))\n",
    "                model.add(Dense(n_outputs, activation='softmax'))\n",
    "\n",
    "                model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=lr), metrics=['accuracy'])\n",
    "\n",
    "                # Use early stopping\n",
    "                early_stopping = EarlyStopping(monitor='val_loss', patience=5) \n",
    "                model.fit(sample_X, sample_y, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[early_stopping], class_weight=d_class_weights)\n",
    "\n",
    "                # Predict the test set results for LSTM model\n",
    "                y_pred = model.predict(testX, batch_size=batch_size)\n",
    "\n",
    "            ensemble_predictions.append(y_pred)\n",
    "\n",
    "        # Combine the predictions from each model\n",
    "        ensemble_predictions = np.array(ensemble_predictions)\n",
    "        ensemble_y_pred = np.argmax(np.mean(ensemble_predictions, axis=0), axis=-1)\n",
    "\n",
    "                # Convert testy from multilabel-indicator format to multiclass format\n",
    "        testy_multiclass = np.argmax(testy, axis=1)\n",
    "        \n",
    "        # Calculate Accuracy, F1 score, Recall, and Precision\n",
    "        accuracy = accuracy_score(testy_multiclass, ensemble_y_pred)\n",
    "        f1 = f1_score(testy_multiclass, ensemble_y_pred, average='weighted')\n",
    "        recall = recall_score(testy_multiclass, ensemble_y_pred, average='weighted')\n",
    "        precision = precision_score(testy_multiclass, ensemble_y_pred, average='weighted')\n",
    "        \n",
    "        print(f'Accuracy with learning rate {lr}: {accuracy}')\n",
    "        print(f'F1 Score: {f1}')\n",
    "        print(f'Recall: {recall}')\n",
    "        print(f'Precision: {precision}')\n",
    "        cm = confusion_matrix(testy_multiclass, ensemble_y_pred)\n",
    "        print('Confusion Matrix:')\n",
    "        print(cm)\n",
    "\n",
    "    return accuracy, f1, recall, precision\n",
    "\n",
    "\n",
    "\n",
    "def run_experiment(repeats, datasetname):\n",
    "    experiment_start_time = time.time()\n",
    "    trainX, trainy, testX, testy = load_dataset(datasetname)\n",
    "    print('Evaluating for ' + datasetname + '...\\n')\n",
    "    data_loading_time = time.time()\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        print('Repeat: ', r + 1)\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "    print(\"Duration of loading data: %d seconds\" % (data_loading_time - experiment_start_time))\n",
    "    print(\"Duration of evaluating model: %d seconds\" % (time.time() - data_loading_time))\n",
    "    print(\"Duration of whole experiment: %d seconds\" % (time.time() - experiment_start_time))\n",
    "    \n",
    "run_experiment(1,'C:\\\\Users\\\\nalla\\\\OneDrive\\\\Provision_PT_838\\\\dataset\\\\Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "434a215c-8983-459a-82cb-63f41dc72bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs:  5\n",
      "Batch size:  128\n",
      "\n",
      "Loading dataset...\n",
      "\n",
      "After stacking...\n",
      "trainX.shape:  (1557162, 115, 1)\n",
      "testX.shape:  (173018, 115, 1)\n",
      "\n",
      "After categorizing...\n",
      "trainy.shape:  (1557162, 11)\n",
      "testy.shape:  (173018, 11) \n",
      "\n",
      "Evaluating for C:\\Users\\nalla\\OneDrive\\Provision_PT_838\\dataset\\Data...\n",
      "\n",
      "Repeat:  1\n",
      "Training model with learning rate: 0.001\n",
      "Training model 1...\n",
      "Training model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nalla\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m12166/12166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4481s\u001b[0m 368ms/step - accuracy: 0.9000 - loss: 0.0870\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nalla\\anaconda3\\Lib\\site-packages\\keras\\src\\callbacks\\early_stopping.py:156: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12166/12166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3765s\u001b[0m 309ms/step - accuracy: 0.9354 - loss: 0.0382\n",
      "Epoch 3/5\n",
      "\u001b[1m12166/12166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2544s\u001b[0m 209ms/step - accuracy: 0.9377 - loss: 0.0352\n",
      "Epoch 4/5\n",
      "\u001b[1m12166/12166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2657s\u001b[0m 218ms/step - accuracy: 0.9382 - loss: 0.0343\n",
      "Epoch 5/5\n",
      "\u001b[1m12166/12166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2767s\u001b[0m 227ms/step - accuracy: 0.9402 - loss: 0.0320\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 99ms/step\n",
      "Accuracy with learning rate 0.001: 0.9927406397022275\n",
      "F1 Score: 0.9924756790212876\n",
      "Recall: 0.9927406397022275\n",
      "Precision: 0.9932590680642815\n",
      "Confusion Matrix:\n",
      "[[98528     0     0     0     0     1     0     0     0     0     0]\n",
      " [    0  5640     1     2     0     0     0     0     0     0     0]\n",
      " [    0     3  2896     2     0     0     0     0     0     0     0]\n",
      " [    2     1     0  2816     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0  8953     1     0     0     0     0     0]\n",
      " [    5     0     0     0     1 10402     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0  4894     0     0  1235     0]\n",
      " [    0     0     0     0     0     0     0  9633     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0  6676     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0 15748     0]\n",
      " [    0     0     0     0     0     0     1     0     0     1  5576]]\n",
      "Duration of loading data: 62 seconds\n",
      "Duration of evaluating model: 17209 seconds\n",
      "Duration of whole experiment: 17271 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import time\n",
    "from sklearn.utils import resample\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy import mean, std, dstack\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Declare a global variable to store the results\n",
    "global_results = {}\n",
    "\n",
    "def load_dataset(path):\n",
    "    # Load input data and output data\n",
    "    print('\\nLoading dataset...')\n",
    "    files = os.listdir(path)\n",
    "    dataX_files = [file for file in files if 'x_' in file]\n",
    "    datay_files = [file for file in files if 'y_' in file]\n",
    "    dataX_files.sort()\n",
    "    datay_files.sort()\n",
    "\n",
    "    dataX = pd.concat([pd.read_csv(path + '/' + file, delimiter=',') for file in dataX_files])\n",
    "    \n",
    "    datay = pd.DataFrame()  # Initialize datay as an empty DataFrame\n",
    "    unique_label = 1\n",
    "    for file in datay_files:\n",
    "        datay_temp = pd.read_csv(path + '/' + file, delimiter=',')\n",
    "        if (datay_temp.iloc[:, 0] == 1).any():  # Check if there are any 1 values in the first column\n",
    "            datay_temp.loc[datay_temp.iloc[:, 0] == 1, datay_temp.columns[0]] = unique_label\n",
    "            if datay.empty:  # If datay is empty, directly assign datay_temp\n",
    "                datay = datay_temp\n",
    "            else:\n",
    "                datay = pd.concat([datay, datay_temp])  # Append only the modified datay_temp\n",
    "            unique_label += 1\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    trainX, testX = model_selection.train_test_split(dataX, test_size=0.10, random_state=42, shuffle=True)\n",
    "    trainy, testy = model_selection.train_test_split(datay, test_size=0.10, random_state=42, shuffle=True)\n",
    "\n",
    "    # Get 3D training data (assuming your data requires this step)\n",
    "    listtrain = [trainX]\n",
    "    listtest = [testX]\n",
    "    trainX = dstack(listtrain)\n",
    "    testX = dstack(listtest)\n",
    "    print('\\nAfter stacking...')\n",
    "    print('trainX.shape: ', trainX.shape)\n",
    "    print('testX.shape: ', testX.shape)\n",
    "\n",
    "    # Calculate number of classes based on unique values in trainy\n",
    "    num_classes = np.unique(trainy).shape[0]\n",
    "\n",
    "    # Convert output data to categorical form\n",
    "    trainy = to_categorical(trainy.values.ravel(), num_classes=num_classes)\n",
    "    testy = to_categorical(testy.values.ravel(), num_classes=num_classes)\n",
    "    print('\\nAfter categorizing...')\n",
    "    print('trainy.shape: ', trainy.shape)\n",
    "    print('testy.shape: ', testy.shape, '\\n')\n",
    "\n",
    "    return trainX, trainy, testX, testy\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import time\n",
    "epochs, batch_size = 5, 128  # Reduced number of epochs and increased batch size\n",
    "print('Number of epochs: ', epochs)\n",
    "print('Batch size: ', batch_size),\n",
    "# Declare a global variable to store the results\n",
    "global_results = {}\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    n_features, n_added_dimension, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\n",
    "    # Calculate class weights\n",
    "    y_integers = np.argmax(trainy, axis=1)\n",
    "    class_weights = class_weight.compute_sample_weight('balanced', y_integers)\n",
    "    d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "    # Define your learning rates\n",
    "    learning_rates = [0.001]\n",
    "\n",
    "    # Initialize a list to store the predictions from each model\n",
    "    ensemble_predictions = []\n",
    "\n",
    "    for lr in learning_rates:\n",
    "        \n",
    "        print(f'Training model with learning rate: {lr}')\n",
    "\n",
    "        for i in range(2):  # Train 2 models\n",
    "            print(f'Training model {i+1}...')\n",
    "\n",
    "            # Randomly sample instances from the training data\n",
    "            indices = np.arange(trainX.shape[0])\n",
    "            sample_indices = resample(indices, replace=True)\n",
    "            sample_X, sample_y = trainX[sample_indices], trainy[sample_indices]\n",
    "\n",
    "            if i == 0:\n",
    "                # Flatten the data for Random Forest\n",
    "                trainX_flat = sample_X.reshape(sample_X.shape[0], -1)\n",
    "\n",
    "                # Convert categorical labels back to 1-D for Random Forest\n",
    "                trainy_flat = np.argmax(sample_y, axis=1)\n",
    "\n",
    "                # Define the model with depth 4\n",
    "                model = RandomForestClassifier(n_estimators=100, max_depth=4)\n",
    "                model.fit(trainX_flat, trainy_flat)\n",
    "\n",
    "                # Predict the test set results for RandomForestClassifier\n",
    "                testX_flat = testX.reshape(testX.shape[0], -1)\n",
    "                y_pred = model.predict_proba(testX_flat)\n",
    "\n",
    "            else:\n",
    "                # Define the LSTM model for the second iteration\n",
    "                model = Sequential()\n",
    "                model.add(LSTM(100, input_shape=(n_features, n_added_dimension), return_sequences=True))\n",
    "                model.add(Dropout(0.2))\n",
    "                model.add(Conv1D(64, 3, activation='relu'))\n",
    "                model.add(MaxPooling1D(pool_size=2))\n",
    "                model.add(Flatten())\n",
    "                model.add(Dense(50, activation='relu'))\n",
    "                model.add(Dense(n_outputs, activation='softmax'))\n",
    "\n",
    "                model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=lr), metrics=['accuracy'])\n",
    "\n",
    "                # Use early stopping\n",
    "                early_stopping = EarlyStopping(monitor='val_loss', patience=5) \n",
    "                model.fit(sample_X, sample_y, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[early_stopping], class_weight=d_class_weights)\n",
    "\n",
    "                # Predict the test set results for LSTM model\n",
    "                y_pred = model.predict(testX, batch_size=batch_size)\n",
    "\n",
    "            ensemble_predictions.append(y_pred)\n",
    "\n",
    "        # Combine the predictions from each model\n",
    "        ensemble_predictions = np.array(ensemble_predictions)\n",
    "        ensemble_y_pred = np.argmax(np.mean(ensemble_predictions, axis=0), axis=-1)\n",
    "\n",
    "                # Convert testy from multilabel-indicator format to multiclass format\n",
    "        testy_multiclass = np.argmax(testy, axis=1)\n",
    "        \n",
    "        # Calculate Accuracy, F1 score, Recall, and Precision\n",
    "        accuracy = accuracy_score(testy_multiclass, ensemble_y_pred)\n",
    "        f1 = f1_score(testy_multiclass, ensemble_y_pred, average='weighted')\n",
    "        recall = recall_score(testy_multiclass, ensemble_y_pred, average='weighted')\n",
    "        precision = precision_score(testy_multiclass, ensemble_y_pred, average='weighted')\n",
    "        \n",
    "        print(f'Accuracy with learning rate {lr}: {accuracy}')\n",
    "        print(f'F1 Score: {f1}')\n",
    "        print(f'Recall: {recall}')\n",
    "        print(f'Precision: {precision}')\n",
    "        cm = confusion_matrix(testy_multiclass, ensemble_y_pred)\n",
    "        print('Confusion Matrix:')\n",
    "        print(cm)\n",
    "\n",
    "    return accuracy, f1, recall, precision\n",
    "\n",
    "\n",
    "\n",
    "def run_experiment(repeats, datasetname):\n",
    "    experiment_start_time = time.time()\n",
    "    trainX, trainy, testX, testy = load_dataset(datasetname)\n",
    "    print('Evaluating for ' + datasetname + '...\\n')\n",
    "    data_loading_time = time.time()\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        print('Repeat: ', r + 1)\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "    print(\"Duration of loading data: %d seconds\" % (data_loading_time - experiment_start_time))\n",
    "    print(\"Duration of evaluating model: %d seconds\" % (time.time() - data_loading_time))\n",
    "    print(\"Duration of whole experiment: %d seconds\" % (time.time() - experiment_start_time))\n",
    "    \n",
    "run_experiment(1,'C:\\\\Users\\\\nalla\\\\OneDrive\\\\Provision_PT_838\\\\dataset\\\\Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13184346-e827-42ff-9bb8-ff24bddacfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "x = [0.0001, 0.0005, 0.001, 0.01, 0.05]\n",
    "y = [99.163, 99.389, 99.274, 95.88, 96.65]\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(x, y, marker='o')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Accuracy vs Learning Rate')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0116cb9-621f-4d56-8a93-7092f46d4d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
